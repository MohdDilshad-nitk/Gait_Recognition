{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1EjEb53EEK9RZKND5dfF8TvoCrFUxqC7r -O /content/data.zip\n",
    "!unzip /content/data.zip -d /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.kgdb_to_csv import process_skeleton_data\n",
    "process_skeleton_data('data/Data', 'data/CSVData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing.data_augmentation import augment_data\n",
    "augment_data('data/CSVData', 'data/AugmentedData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply JMM, Gait cycle extraction, RoPE, contrastive learning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from data_loaders.train_test_val_loader import create_fixed_splits\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Directory containing the dataset\n",
    "data_dir = 'data/AugmentedData'\n",
    "sb = ''\n",
    "try:\n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_fixed_splits(data_dir=data_dir, batch_size=32)\n",
    "\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "    # Get a sample batch\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    # print(sample_batch)\n",
    "    print(\"\\nSample batch contents:\")\n",
    "    for key, value in sample_batch.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"{key} shape: {value.shape}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "    # Save dataset statistics\n",
    "    stats = {\n",
    "        'num_training_sequences': len(train_loader.dataset),\n",
    "        'num_validation_sequences': len(val_loader.dataset),\n",
    "        'num_test_sequences': len(test_loader.dataset),\n",
    "        'max_sequence_length': train_loader.dataset.max_len,\n",
    "        'num_joints': 20,\n",
    "        'num_persons': len(train_loader.dataset.person_ids)\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([stats]).to_csv('dataset_statistics.csv', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing dataset: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Transformer.model import SkeletonTransformer\n",
    "from Transformer.trainer import SkeletonTransformerTrainer\n",
    "\n",
    "# Create model and trainer\n",
    "model = SkeletonTransformer(\n",
    "    num_joints=20,\n",
    "    d_model=60,\n",
    "    nhead=1,\n",
    "    num_encoder_layers=1,\n",
    "    dim_feedforward=256,\n",
    "    dropout=0.2,\n",
    "    num_classes=164\n",
    ")\n",
    "\n",
    "trainer = SkeletonTransformerTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    save_dir='trained_models'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer.train(\n",
    "    num_epochs=60,\n",
    "    resume_path=None  # Set to checkpoint path to resume training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer.evaluater import evaluate_model, print_evaluation_results, plot_confusion_matrix\n",
    "# Evaluate model\n",
    "results = evaluate_model(model, test_loader)\n",
    "\n",
    "# Print results\n",
    "print_evaluation_results(results)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
